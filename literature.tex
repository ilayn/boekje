\chapter{A Brief and Opiniated Literature Survey}\label{chap:litsurvey}

The teleoperation systems are structurally interesting and equally challenging 
systems. This is especially true from a system theoretical point of view. As an example, 
if we just focus on the local and the remote devices that would be used for manipulation, 
we see that they are, whether linear or nonlinear, motion-control systems with well-studied 
properties. Hence, one can view the open-loop teleoperation system as a system with a block 
diagonal structure. However, unlike the typical motion-control systems, these two disjoint systems must be stabilized 
simultaneously by the same controller (delayed/undelayed local control loops can be seen as a structured central
controller) that is performing sufficiently in order to ``fool" the user such that the user feels 
a force feedback as if s/he is actually operating at the remote medium. Hence, outputs of each system become
exogenous inputs of the other and these are regulated by the to-be-designed controller. Therefore, it's this controller 
that makes a teleoperation system perform adequately or, as in many situations, drive to instability.


For example, in the case of free-air motion (i.e. the remote device is free to roam in the remote site), the human force input 
to the local device and/or the position of the local device should be tracked by the remote device. In the case of a 
hard-contact of remote device with the environment, however, these inputs should be counteracted  if the force vector points into 
the obstacle. Hence, the force signal is simultaneously tracked for mimicking the user motion and  
is defied in case of a resisting force at the remote site. If this is not enough, when the user suddenly decides to release the 
local device, this resistance should die out as soon as possible, preventing a kickback. As an example, when a user leans to a wall located at 
position $x_0\!\!\uparrow$, applying a horizontal force and then retreats, it is not expected that the wall continues to 
push the user even after the user has the position $x<x_0$. There are a few other scenarios that would further complicate 
the requirements. In short, the user and the environment properties are time-varying and make it difficult to design a control 
law such that these and many other details are handled properly simultaneously. 


With this short motivation, we can safely claim that looking at the overall system as a motion control 
system is not sufficient in terms of complexity (though necessary). In general, motion tracking specifications 
are a subset of the general performance requirements of the bilateral teleoperation systems. 

%\begin{rem}
%A similar line of reasoning has been given in \cite{buergerhogan1}. But for reasons that are 
%not known to us,  the authors chose to see the classical loop shaping as the sole servo control method. Moreover, modern 
%control theory offers a few options to avoid the obstacles that are given as impossibilities in their paper. Therefore, 
%we emphasize that the difference here is merely about the problem formulation and is not about the 
%limits of performance\footnote{We refer to the elegant book \cite{boydbarratt} for a detailed investigation of the 
%limits of performance.}. 
%\end{rem}


The inception of the bilateral teleoperation technology is often attributed to the work 
of Raymond Goertz in Argonne National Laboratories, \cite{goertz} (In \cite{basanezsuarez}, 
it's traced back to Nikola Tesla and, in \cite{sheridan89}, even some 16th century tools are accepted as precursors 
of the modern teleoperation). The main motivation of Goertz' work (similarly later in Europe 
by Vertut \cite{vertutcoiffet}) was handling and manipulating nuclear material, thus the very 
first teleoperators were purely mechanical to cope with the hostile environment conditions. Though not much 
happened in terms of commercial product realizations, the concept of telemanipulation kept its appeal 
and a large body of research was reported until the 1980s. In that decade, with the help of the 
ever-increasing computational power and the popularity of Virtual Reality (VR), teleoperation 
technology received more attention for a possible use in the space-, underwater-, medical-related 
tasks. Together with the advances in control theory and network theory (e.g. \cite{miyazaki,furuta}), 
a more systematic control methodology is adopted. Especially, stability analysis results that can be 
related to design guidelines (physical parameter bounds, bandwidth limitations etc.) are utilized
and limits of performance were explored. A particular phenomenon, namely the destabilizing effect 
of the delays in the teleoperation, lead the experts of the field to delve more into the systematic 
analysis tools and qualitative aspects of teleoperation. Especially, the use of the concepts; passivity, 
scattering transformations, and wave variables have become the standard methods of analysis and synthesis
(see, e.g., \cite{hannaford89,andersonspong,nieslotine}). We will start to summarize the advances from this 
point as this thesis is precisely built on top these systematic analysis and synthesis results gathered in 
the last two decades. However, the reader is refered to \cite{hokayemspong,burdea}, 
and \cite{sheridan89} for a more detailed overview including other practical aspects of teleoperation analysis and 
the hardware developments with a more historical perspective which we will omit here. 


As we keep on narrowing down our focus to control theoretical parts of this challenging problem, we have to 
note that many parts of the bilateral teleoperation problem can be scrutinized under different frameworks. 
Hence, there is no shortage of techniques for which bilateral teleoperation problem is an ideal 
test case. Among the plethora of methods, for example, the variation of human and environment properties give 
naturally rise to a robust or an adaptive control approach, the hard-contact problem can be analyzed under 
switched control systems, jump control systems or constrained linear systems etc. Before we go into the 
details of the proposed methods of this thesis, let us sample a few important and successful approaches 
reported so far together with their shortcomings if any. We emphasize that the literature covered here is 
far from comprehensive and deliberately shaped with pragmatic intentions. Hence a large body of research is 
left out. This is certainly not due to their lack of thoroughness or else, but simply due to the irrelevance 
to the purpose of this chapter.


\begin{figure}%
%http://chat.stackexchange.com/transcript/message/4857161#4857161
\centering
\begin{tikzpicture}[scale=1,manstyle/.style={line width=4pt,line cap=round,line join=round}]
\node[rectangle,draw,minimum height=3cm,minimum width=3.8cm] at (0.5cm,0)     (a) {};
\node[rectangle,draw,minimum height=3cm,minimum width=3.8cm] at (1.5cm,1cm) (b) {};
\foreach \x in {north east,north west,south east,south west} \draw (a.\x) -- (b.\x);
\node[rectangle,draw,minimum height=3cm,minimum width=3.8cm] at (5.5cm,0)     (a) {};
\node[rectangle,draw,minimum height=3cm,minimum width=3.8cm] at (6.5cm,1cm) (b) {};
\foreach \x in {north east,north west,south east,south west} \draw (a.\x) -- (b.\x);
\node[fill,circle,inner sep=2.5pt,outer sep=1pt] at (-0.2mm,7.1mm) {};
\draw[manstyle] (0,0.5cm) -- ++(0,-1.2cm);
\draw[manstyle] (-1.5pt,0) -- ++(0,0.5cm) (1.2pt,1pt) --(0,5mm)--++(-45:4mm);
\draw[line width=1mm,fast cap-fast cap] (0.5cm,0.2cm) -- ++(0.5cm,0);
\begin{scope}[xshift=1.3cm,-stealth,black!20]
\draw (0,0,0) -- (0,0,1); \draw (0,0,0) -- (0,1,0);\draw (0,0,0) -- (1,0,0);
\end{scope}
\begin{scope}[xshift=4.7cm,-stealth,black!20]
\draw (0,0,0) -- (0,0,1); \draw (0,0,0) -- (0,1,0);\draw (0,0,0) -- (1,0,0);
\end{scope}
\begin{scope}[shift={(1.4cm,-0.2cm)}]
\draw (0,0) -- (0.9cm,0) (0.45,0) circle (1.5mm);
\path [postaction={pattern=north west lines},fill=white] (0cm,0cm) rectangle (0.9cm,-0.16cm);
\draw[line width=1.5mm,round cap-round cap] (0.475cm,0.05cm) -- ++(110:7mm);
\draw[line width=1mm,round cap-round cap] (0.475cm,0.05cm) ++(110:6.3mm) --++ (220:5mm);
\end{scope}
\begin{scope}[shift={(5.4cm,-0.2cm)},cm={-1,0,0,1,(0,0)},transform shape]
\draw (0,0) -- (0.9cm,0) (0.45cm,0) circle (1.5mm);
\path [postaction={pattern=north west lines},fill=white] (0cm,0cm) rectangle (0.9cm,-0.16cm);
\draw[line width=1.5mm,round cap-round cap] (0.475cm,0.05cm) -- ++(110:7mm);
\draw[line width=1mm,round cap-round cap] (0.475cm,0.05cm) ++(110:6.3mm) --++ (220:5mm);
\end{scope}
\draw[line width=1mm,fast cap-fast cap] (5.8cm,0.2cm) -- ++(0.5cm,0);
\begin{scope}[shift={(6.6cm,0.4cm)}]
\draw[thick]
\foreach \i in {1,2,...,10} {%
  [rotate=(\i-1)*36]  (0:2mm)  arc (0:12:2mm) -- (18:2.4mm)  arc (18:30:2.4mm) --  (36:2mm)
};
\node[circle,draw,inner sep=2pt,fill] (merkez) at (0,0) {};
\end{scope}
\begin{scope}[shift={(6.85cm,0cm)},scale=1.2]
\draw[thick]
\foreach \i in {1,2,...,10} {%
  [rotate=(\i-1)*36]  (0:2mm)  arc (0:12:2mm) -- (18:2.4mm)  arc (18:30:2.4mm) --  (36:2mm)
};
\node[circle,draw,inner sep=2pt,fill] (merkez) at (0,0) {};
\end{scope}
\begin{scope}[shift={(6.8cm,0.5cm)},scale=0.8]
\draw[fill] (0.5mm,0.5cm) rectangle (0.49cm,0.6cm);
\draw[fill,postaction={pattern=north west lines,pattern color=white}] (0.2cm,0.5cm) -- ++ (0,-0.4cm) -- ++ (-45:1mm) --++(45:1mm) --++ (0,0.4cm) --cycle;
\end{scope}

\end{tikzpicture}

\caption{General Teleoperation System}%
\label{fig:teleop}%
\end{figure}

\section{Modeling of Bilateral Teleoperation Systems}\label{sec:litchapmodeling}

The dominating modeling paradigm of bilateral teleoperation systems is the two-port network approach. Consider the quote taken from
\cite{hannaford89} published in 1989:
%\begin{mdframed}[style={userdefinedwidth={0.8\textwidth},align=center,outerlinewidth=3pt,innerlinewidth=0pt,outerlinecolor=black!10,roundcorner=3pt}]
\begin{quote}
%In this paper, development of the analytical framework is complemented by modeling of an actual teleoperator system.
The modeling approach is to transform the teleoperation system model into an electrical circuit and simulate it using
SPICE, the electronic circuit simulation program developed at UC Berkeley.
\end{quote}
%\end{mdframed}


As seen from Hannaford's motivation, the computer-based simulation tools are used extensively since then. Arguably
this is one of the main reasons why network based electrical circuit based modeling dominated the teleoperation literature. 
Reinforced with the circuit simulation tools, experts of the field started to construct analogies that go beyond
a mere mechanical-electrical system analogy. Arguably, the most prominent concept borrowed from these analogies is the two-port network 
view of the bilateral teleoperation systems. The reader is referred to \Cref{chap:apdxnetwork} for a short recap of network theory.
Today, the quoted convenience also applies to almost all physical systems i.e. one can simulate arbitrary models via many 
computational packages. Yet, it's a de facto standard to use the circuit modeling while the teleoperation devices are mostly 
mechanical. Hence, it's not clear whether the benefit of such an artificial step didn't vanish. Once the system is represented 
by a mathematical model, as it is demonstrated in the later sections, the mechanical/electrical analogy is, roughly, an equivalence
based on the resulting model and works in the electrical$\to$mechanical direction too. Therefore, to the best of our knowledge, the 
circuit based modeling is merely a convention rather than a requirement.

\subsection{Two-port Modeling of Teleoperation Systems}

In the teleoperation context, if one uses the ``load-source" analogy for the manipulated environment 
and the human, then the system models all the bilateral interaction between the load and the source 
ports (as in \Cref{fig:portrep}). This modeling view is quite powerful since the components are described via their input/output 
(or external) properties i.e. effort variable/flow variable relations (e.g. force/velocity, voltage/current etc.). Also, the non/linearity
properties of the components are not relevant at the outset if we are only interested in energy exchange which is the basis
of the so-called Time-Domain Passivity Methods \cite{hannafordryu} which we will mention later in this chapter. Thus, 
the user, the control system, the environment, the remote and local devices and communication delays are seen as 
$1-$ and $2-$ports exchanging energy in time. Since the external behavior of the ports can be characterized completely by the 
current and the voltage drop across the terminals, it is indeed very convenient to model these components as 
interacting ``black boxes'' (See \Cref{fig:portrep}).


\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
\centering
\begin{tikzpicture}[>=stealth,baseline=15mm,
every node/.style={draw,minimum size=1cm}]
\node (deltas) at (0,0) {$\Delta_l$};
\node[left=of deltas] (g) {$G$};
\node[left=of g] (deltal) {$\Delta_s$};
\tikzset{every node/.style={draw,circle,inner sep=1pt,fill=white}}
\foreach \y in {s,l}{
    \node at ({$(g)!0.5!(delta\y)$} |- {g.40}) (circ1\y){};
    \node at ({$(g)!0.5!(delta\y)$} |- {g.-40})(circ2\y){};
};
\draw (circ1l) -- (deltal.40) (circ2l) -- (deltal.-40)
(circ1s) -- (deltas.140) (circ2s) -- (deltas.-140);
\draw[->] (circ2s) -- (g.-40) (circ1s) -- (g.40);
\draw[->] (circ2l) -- (g.-140) (circ1l) -- (g.140);
\end{tikzpicture}
\caption{}
\label{fig:portrep}
\end{subfigure}%
\begin{subfigure}[b]{0.5\textwidth}
\centering
\begin{tikzpicture}[>=stealth,scale=0.5, transform shape]
\matrix (G) [draw,matrix of math nodes,inner sep=1mm,row sep=1mm,ampersand replacement=\&]{ G_{11} \& G_{12}\\ G_{21} \& G_{22}\\};
\matrix (delta) at (0,3) [outer sep=0,draw,matrix of math nodes,inner sep=0.5mm,ampersand replacement=\&]{\Delta_s \& \\ \& \Delta_l\\};
\draw[->] (G.160) -| ++ (-0.4,0.8) node[draw,circle,fill=white,inner sep=2,label={[inner sep=0]0:$\scriptstyle -$}] {} |- (delta.160);
\draw[->] (G.200) -| ++ (-0.7,0.6) node[draw,circle,fill=white,inner sep=2,label={[inner sep=0]0:$\scriptstyle -$}] {} |- (delta.200);
\draw[<-] (G.20) -| ++ (0.4,0.5) |- (delta.20);
\draw[<-] (G.-20) -| ++ (0.7,0.5) |- (delta.-20);
\end{tikzpicture}
\caption{}
\label{fig:nom_net}
\end{subfigure}
\caption{Two representations of a 2-port network.}
\end{figure}

Clearly, thanks to this modeling method, we don't even need to 
know exactly what $\Delta_l,\Delta_s$ blocks are, except their class (e.g. linear/nonlinear, time invariant/time varying etc.) to analyze 
the system via $G$.  Thus, the problem of modeling of the human arm or of the uncertain environment
is circumvented. However, due to the same reasoning, passivity property does not distinguish particular systems as long as they are 
passive. For this reason, some of the crucial information is lost about these specific ports. In other words, we discard
any impedance or admittance relations shared by the port variables.

We have mentioned the ports and energy transfer between them as the main modeling paradigm so far. Energy based modeling is 
the natural basis for bond-graphs too. Bond-graphs, much like port representations, are graphical tools to model the dynamical 
systems via energy balancing between subcomponents (See \cite{gawthrop} for an introduction). In other words, the bond-graphs are built on top of the notion 
of bonds representing the instant energy or power exchange between nodes via edges drawn between them. Therefore, bond-graphs
already presents a powerful framework for abstraction of the bilateral interaction between the local and the remote site. For a 
classical use of bond-graphs in impedance control, the reader is referred to the Hogan's trilogy (\cite{hogan:1,hogan:2,hogan:3}).
There are also many studies with application focus, e.g., \cite{krishnaswamy} using hydraulic systems for bilateral teleoperation
among many others. 



\subsection{Assumptions on the Local and Remote ``Ports''}

Up to this point, we have touched upon how network theory offered a great opportunity for modeling the 
teleoperation systems. Still, to invoke the stability analysis and synthesis results of the network thoery there is a need 
to further distinguish $\Delta_s,\Delta_l$ from the universum of $1-$ports. Otherwise there is not much we can conclude from such an 
interconnection, put differently, they can be any arbitrary model with arbitrary behavior set as long as they respect the port 
condition. This is obviously not sufficient to capture the real physical interaction that teleoperation systems embody. 

In teleoperation and haptics literature, it is customary to assume that the load and the source terminations as ``passive''
mathematical operators (see \Cref{chap:apdxnetwork}). By this hypothesis, the main tool that one has is the physical-interaction-based approach. 
Hence the view of the designer is tuned to see the energy interaction between two distant media. This approach treats the human and the 
environment as passive elements with additional effort sources modeling the intentional force input to the system and the 
controller is viewed as the energy regulator preventing excess energy causing the system go unstable. Moreover, as we have
briefly summarized in \Cref{chap:apdxnetwork} and in the analysis section below, one can use the network theory based conditions 
to assess the stability and performance conditions thanks to this hypothesis.

This brings us to the discussion of the justification of the validity of such an assumption as it is generally not given in full generality in the
literature. If one scans through the literature about the passivity of human operators, it is Hogan's paper \cite{hogan89}
that is almost universally cited. The striking detail is, however, that Hogan never claims that the human exhibits a passive
behavior. Instead he clearly shows that under certain conditions, human behavior is indistinguishable than that of a 
passive system: 
\begin{quote}
Thus, despite the fact that the
limb is actively controlled by neuro-muscular feedback, its apparent
stiffness is equivalent to that of a completely passive
system. In the light of Colgate's recent proof [3]\footnote{Reference 
\cite{colgatehogan88} of this thesis.} that an
apparently passive impedance is the necessary and sufficient
condition for a stable actively-controlled system to remain stable
on contact with an arbitrary passive environment, this
experimental result strongly suggests that neural feedback in the
human arm is carefully tuned to preserve stability under the
widest possible set of conditions.
\end{quote}
Moreover, the task that is given to human operators and analyzed afterwards is about making the human 
be as passive as possible. The task is, roughly speaking, holding a handle which is perturbed by random disturbances and 
trying to keep the handle still at a predefined position on the 2D plane. Hence, the task is simply to mimic a passive 
component that is, again roughly, a mass-spring-damper system. Had it been the case that the human would exhibit non-symmetric 
stiffness matrix, it would simply be a failure of the test subject (regardless of the physical limitations). Note that this 
is a plausible assumption for the rehabilitation tasks. The other possibility would then be is that the test subject was unable to keep up 
with the changes, or using the control theory jargon, the bandwidth of the subject was lower than the required agility to 
perform the test adequately.  The well-known phenomenon of such behavior is the ``pilot induced oscillations'' in which the pilot
of an aircraft, while trying to stabilize the aircraft, via overcorrection inputs, destabilizes the system due to many distinct reasons 
(response time of the pilot and thus the phase lag with response time of the aircraft etc.). We refer to the interesting 
report \cite{mcruer} for a more detailed exposition. Moreover, if for some reason, the task at hand is to prevent the system 
to reach a steady state at a certain position and the perturbations are applied accordingly i.e., to create a virtual potential, 
the results obtained from the experiments would most probably different from that of \cite{mussa85}. Thus, it's worth mentioning 
that the passivity of the human is closely linked to the passivity of the environment. 


\begin{rem}
A particular detail should be clarified about the measurements taken in \cite{hogan89}. It is stated that: 
\begin{quote}
While normal human subjects held the handle of the manipulandum at a stable position
in the workspace, small perturbations were applied. Measurements
of the human's restoring force were made after the system
had returned to steady state following the perturbation but before
the onset of voluntary intervention by the subjects.
\end{quote}
Therefore, it is emphasized that only the involuntary response is taken into account during the measurements in order to
capture the natural properties human arm before the human correction intervenes. Note that, this does not imply that the
measurements treat the human arm as a bulky cybernetic device which might only be possible in case of an improbable amputation.
In fact, in this setting, the voluntary input of the human is not included to the analysis, since the human necessarily puts in
energy, at the very least, to move the local device. 
\end{rem}

The question of how, then, a human can actually move anything while remaining passive is one that makes the whole 
story more complicated. The voluntary input of the human is taken as an exogenous input to the system. This is due to the 
fact that, in passivity based analysis, the closed loop stability is tested against square integrable functions of time 
modeling the finite energy inputs by the human which will be covered in \Cref{sec:litchapanalysis} in this chapter.  

A keen eyed reader would spot that this is not inline with Hogan's remark since the human force input has 
alredy been considered in the apparent stiffness measurements. In other words, without the human's active control, the passivity 
argument does not hold as the stiffness matrix might be non-symmetric and hence would have a non-zero curl. Therefore, we have to further
separate the human force into two parts, namely, the active neuromuscular feedback force and the voluntary and cognitive force 
input applied to the system. How this is usually performed is not clear in the literature. To the best of our knowledge, this 
issue is addressed explicitly (but still briefly) only in \cite[Sec. II.B]{kazeroonitsay} and references therein.

This ambiguity becomes much more important since the control oriented focus of this thesis necessitates that we concentrate on
worst cases rather than the experiments performed within the cognitive range of human operators. In other words, we are interested in
the cases where things go wrong due to many other various reasons, sampling distubances, mesurement noises, directionality etc. Therefore
it cannot be a satisfactory argument if stability depends on the user's neuromuscular feedback or simply user's stabilization capabilities. 
In order to use the bilateral teleoperation devices in real-life cases, stability should be addressed regardless of human actions. Hogan's 
findings are not sufficient for supporting the passivity assumption often found in the literature. 


In summary, the passivity of the human and the environment (virtual environment in haptics/virtual reality applications), is 
only plausible in certain occasions which should be verified in order to assume that the corresponding mathematical models 
are passive. Nevertheless, analysis and synthesis methods that invoke this assumption lead to many real-world implementations 
with varying degree of realism. We argue that the success of these methods is due to the conservatism of the analysis/synthesis tools
and does not validate the passivity hypotheses on the respective models.

A compact version of the argument above is given by Yokokohji and Yoshikawa in \cite{yokokohjiyoshikawa}: 
\begin{quote}
Passivity of the system can be a
sufficient condition of stability only when the system interacts
passive environments. In the case of master-slave systems, if
we could assume that the operator and the environment are
passive systems, then the sufficient condition of stability is
that the master-slave system itself must be passive. Strictly
speaking, however, the operator is not passive because he/she
has muscles as the power source. Colgate et al. [21]\footnote{Reference 
\cite{colgatehogan88} of this thesis} mentioned
that even if the system has an active term, the system stability
is guaranteed unless the active term is in some way state dependent.
Obviously, the operator is passive when $\tau_{op}= 0$.
Therefore, we will give the following assumption about $\tau_{op}$:
\emph{``The operators input $\tau_{op}$ independent to the state of the
master-slave system. In other words, the operator does not
generate $\tau_{op}$ that will cause the system to be unstable.''}
Dudragne et al. [3] gave a similar assumption in order to use
the concept of passivity for stability distinction. The above
assumption seems tricky in a sense, but it is necessary to ensure
the system stability by the passivity.
\end{quote}

\noindent Finally, a supplementary remark is also given by Buerger and Hogan in \cite{buergerhogan1}: 
\begin{quote}
When passivity is used as a stability objective, the only assumption
made about the environment is that it, too, is passive.
This is likely sufficient to guarantee coupled stability with humans
(though, to date, it has not been conclusively proven that
human limbs are passive; see [29]\footnote{Reference \cite{hogan89} in this thesis} for an argument for treating
them as such). However, given the properties of human arms
described above, passivity is unnecessarily restrictive. Our experience
has shown that some controllers that are known to be
nonpassive are adequately stable in clinical rehabilitation tasks [26].
\end{quote}


We should mention here that Hogan's paper together with other identification experiments are extremely important for many
fields and needs no motivation. The discussion above only points out that the inference that follows from his results, 
is not inline with the results themselves. 

The idea of modeling the teleoperation as a two-port network seems to have multiple origins and we have no reference to 
point out to a common source. However, in general, the popularity of two-ports can be attributed to 
\cite{andersonspong,nieslotine,rajuphd,hannaford89,yokokohjiyoshikawa}. 

\subsection{Uncertain Models of Bilateral Teleoperation for Robustness Tests}\label{sec:lit:uncmodel}

Another possibility of modeling the human arm and its cognitive input is to define an input force signal ``filtered'' by the 
human arm impedance\footnote{The term \emph{impedance} is used in a more general sense than its common usage to denote
LTI transfer functions such that no distinction is made between linear and nonlinear or time-invariant and time-varying 
operators.} 

Various studies pointed out that the identification experiments suggest a mass-spring-damper system pattern is evident
in the frequency response data of the human arm recorded under various task performance similar to the one given in \cite{hogan89}.
The general method is to instruct the human to perform a specific task and then perturb the hardware with certain predesigned
disturbance signals such that the output can be evaluated to obtain a mathematical model. In the literature, the model structure
is often set a priori to be a second order transfer function and the parameters are optimized to minimize the mismatch between
the experimental and predicted response. It is also well-known that the human can change the inherent impedance of the arm during
the task execution (see, e.g., \cite{tsujimorasso}). Therefore, the studies are performed in the ranges where it is safe to assume 
that the human arm characteristics are constant or constant up to negligible changes. 


The modeling is straightforward via uncertain mass-spring-damper system differential equation manupulations. Suppose the human arm
assumes the second order model: 
\[
M(\Delta_1)\ddot{x} + B(\Delta_2)\dot{x} + K(\Delta_3)x = F_h -F_m
\] 
where $F_h,F_m$ denote the human force and the force feedback inputs, respectively. Then choosing a multiplicative or additive uncertainty 
structure and via basic linear fractional transformations, the signal relations are converted to the interconnection shown in 
\Cref{fig:lit:figunc}. The arrows are deliberately left out as it's up to the designer to get different immitance models.
\begin{figure}%
\centering
\begin{tikzpicture}
\matrix[draw,matrix of math nodes] (m) {\Delta_1 &&\\&\Delta_2 &\\&&\Delta_3\\};
\node[below=1cm of m,draw,minimum size=2.0cm] (g) {$G_{nom}$};
\draw (g.155) -| ++(-1cm,1cm) |- (m.west);
\draw (g.25) -| ++(1cm,1cm) |- (m.east);
\draw (g.-155) -- ++(-1cm,0cm) (g.-25) -- ++ (1cm,0cm);
\end{tikzpicture}
\caption{Uncertain model representation by taking out the uncertainty blocks}%
\label{fig:lit:figunc}%
\end{figure}


Many studies have appeared in the literature regarding such modeling and the majority of these assume a 
mechanical model of order from two to five. Note that this is an assumption made a priori and only applies 
to the specific task performed by the human in the experiment from which the frequency response data is 
collected. The commonly utilized models can be found in \cite{kazeroonitsay,tsujigoto,kosuge,colgate1,speich,
fucavus,buergerhogan1,leungfa,husalculoewen,andrifour,laroche}. 
Obtaining these measurements are time-consuming and difficult to parameterize. For this reason, although
the results along this direction are scarce, they are, as in the passivity case, very valuable. 

The disadvantage of such parametrization of the human arm is contrasted with the passivity approach methods
invoking the argument of time-varying nature of the arm parameters. It is often rightfully argued that the 
uncertainty ranges in which the stiffness and damping (and partially inertial) coefficients change, are too 
large to be considered in the structured singular value based robustness tools. Moreover, many auxiliary 
effects such as the visual feedback, cognitive lag of the brain etc. are not considered in the identification 
experiments, but in the passivity approach all of these are lumped into a single port condition. Obviously, 
the main difficulty is to get a model (out of hypothetical insights, identification experiments etc.) which is
not required in the passivity approach.

The paper \cite{leelee} offers an interesting alternative as it tries to incorporate many of the aforementioned 
effects, however, the results are prospective and yet to be utilized. 



\section{Analysis}\label{sec:litchapanalysis}

The stability analysis is one of the major problems in designing stable yet high-performance teleoperation 
systems. It's often not feasible to manually tune some local controllers and make test subjects use it in order to verify the
design specifications. Moreover, relying only on the experiments can miss an important destabilizing scenario if the field 
experiments do not cover that particular case. Hence, an a priori certificate of stability is much sought after. The stability 
analysis can also give some guidelines about the parameter selection in the hardware design phase and can lead to minimized 
design iterations. Therefore, having a realistic stability test is essential in building these systems. 

Similar to the modeling section, the analysis in the literature extensively relies on network theory based results. In fact 
this is where the network theory stands out as a complete tool for analysis and synthesis of bilateral teleoperation systems
via the celebrated hypothesis that human and the environment models are passive.  

The common terminology for stability is somewhat different than that of the contemporary control theory as \emph{nominal stability} 
is used for the stability properties of isolated two disjoint media and when the interaction is setup between these two media the closed-loop 
stability problem is called \emph{coupled stability}. To the best of our knowledge, this terminology is introduced in 
\cite{colgatehogan88} hence we refer to this paper (or Colgate's thesis \cite{colgatephd}) for a more detailed motivation. 


It's also worth mentioning that the passivity and stability is used often interchangeably and also usually referred to the classical texts
\cite{haykin,mitra69,chen91} for the precise definitions. Hence, there is a little guesswork required to classify the stability definitions given in the
literature. The important distinguishing point is that the marginal stability is often accepted in the definition of stability results since
it arises frequently in lossless (hence passive) models where energy conservation is assumed. However, the analysis results often 
rely on such assumptions do not guarantee asymptotic interconnection stability but only lead to certain passivity 
properties of the interconnection (see \cite[Thm. 6.1]{khalil} and \cite[Sec. V]{lawrence} for the discussion on strict passivity).  

As given in \Cref{sec:litchapmodeling}, passivity property is crucial to many studies in the literature. The direct physical interpretation
of the abstract concepts gives even more appeal to such energy book-keeping methods. Another advantage of passivity methods is that 
the nonlinear counterparts of the results are also available in the literature and relatively easy to utilize. 

\begin{thm} The negative feedback connection of two passive systems is passive. The negative feedback connection of a passive system with
a strictly passive system is asymptotically stable.\end{thm}

Note that, this result is valid for both nonlinear and linear systems. Invoking the theorem twice on the teleoperation system allows us to conclude that,
under the passivity assumption of the human and the environment, if the two-port is  passive then the interconnection is passive. Moreover, if any of 
the involved operators is strictly passive the teleoperation system is asymptotically stable. 

\begin{figure}%
\centering
\includegraphics[width=0.6\columnwidth]{\impath/literature/train}%
\caption[A transparent two-port network with passive terminations]{A transparent two-port network with passive 
terminations. The actuation of the railcar is taken as state-independent input to the system. (Source: Fred Dean Jr., 
\href{http://www.flickr.com/photos/be216cd1/5971825854/}{[Flickr:Fred Dean Jnr]})}%
\label{fig:lit:train}%
\end{figure}


The passivity assumptions are not necessary for stability but sufficient. There exist stable interconnections that involves nonpassive 
subsystems. Therefore, the conservatism brought in by passivity theorem is quite high (especially in the nonlinear case). Facetious as it 
may seem, the test also takes into account the port terminations shown in \Cref{fig:lit:train} for a table-top joystick. We have to emphasize that
the three-carriage railcar with two cabs, is a valid, almost perfectly transparent two-port network. It's that conservative.


The major disadvantage of the passivity methods is that the procedure is focused almost only on the 
energy exchange and performance specifications are very difficult to formulate and also difficult to integrate 
into the analysis and synthesis steps using only the inner product structure. As an example, the signals that are not port variables such as position errors,
and nonlinear effects that are functions of these signals, can't be utilized easily in the performance specifications. 
Same difficulty arises in the normed space structures though much can be achieved. Unfortunately, much sought after $\LL_\infty$ methods are not mature enough to handle any practical system. 


Another disadvantage is that the power- or the energy-based analysis, due to the inner-product structure, can not distinguish the individual 
signal properties. Consider the ideal case where the human and the local device is pushing each other and cancelling each other's contribution. 
In this case the external or observable energy exchange based on the port variables is zero (negligible) which can not be distinguished from 
the case of not touching at all (a small motion on the device). 


When the network model is assumed to be Linear Time Invariant (LTI), the frequency domain methods
allow us the analyze the teleoperation systems for stability and performance. The most common stabiliy analysis tool for such 
models is the Llewellyn's stability criteria (also often called absolute stability theorem or unconditional stability theorem). 
For linear networks, the following definitions seem to be used quite widely (modified from \cite{chen91}): 

\begin{define}[Potential Instability at $\iw_0$] A two-port network is said to be potentially unstable at $\iw_0$ on the real frequency, 
if there exist two passive one-port immitances that, when terminated at the ports, produce a natural frequency at $\iw_0$ overall network.   
\end{define}

\begin{define}[Absolute Stability at $\iw_0$] A two-port network is said to be absolutely stable at $\iw_0$ on the real frequency, 
if it is not potentially unstable at $\iw_0$.   
\end{define}

If moreover,  human, and the environment models are assumed to be LTI then absoulte stability theorem is an exact stability characterization. 

\subsection{Llewellyn Stability Criteria}\label{sec:llewellyn}
The well known conditions for stability of a two-port network, formulated in \cite{llewellyn,bolinder,rollett}, are recalled in the 
following theorem. An explicit indication of the frequency dependence is  {often} omitted for notational convenience.
\begin{thm}[Llewellyn's Criteria]\label{thm:apdx:llw}
A two-port network $N$,  described by its transfer matrix
\[
N(\iw) = \pmatr{N_{11}(\iw) &N_{12}(\iw)\\N_{21}(\iw) &N_{22}(\iw)}
\]
and interconnected to passive LTI termination immitances as in \Cref{fig:portrep}, is stable if and only if
\begin{equation}R_{11} > 0\text{ or } R_{22} > 0,\label{eq:lit:llew2}\end{equation} and
\begin{equation}4\left(R_{11}R_{22}+X_{12}X_{21}\right)\left(R_{11}R_{22}-R_{12}R_{21}\right)-\left(R_{12}X_{21}-R_{21}X_{12}\right)^2 > 0\label{eq:lit:llew3}\end{equation} 
or
\begin{equation}2R_{11}R_{22}-\abs{N_{12}N_{21}}-\Re{N_{12}N_{21}} > 0\tag{\ref{eq:lit:llew3}$'$}\label{eq:lit:llew3p}\end{equation}
for all $\omega\in\Realext$, where $R_{ij}$ and $X_{ij}$ denote the real and imaginary parts of $N_{ij}$ respectively.
\end{thm}


As shown in \cite{rollett}, the conditions stated in \Cref{thm:apdx:llw} are invariant under immitance substitution. This result forms the 
basis for almost all passivity-based frequency domain bilateral teleoperation stability analysis approaches in the literature. 
We would also derive this theorem from an IQC perspective and show that it is actually the passivity counterpart of the 
of the $D$-scalings in the $\mu$-tools. Thanks to the frequency domain formulation, it is possible  to rewrite the condition 
\eqref{eq:lit:llew3} as a fraction and see the problematic regions in which the fraction gets close to or crosses to the instability, 
together with one of the conditions given in \eqref{eq:lit:llew2}. 


\begin{figure}%
\centering
\begin{tikzpicture}[>=stealth]
\node[draw,minimum size=1cm] (h2) {$H_2$};
\node[draw,minimum size=1cm, above=1cm of h2] (h1) {$H_1$};
\node[draw,circle,inner sep=1mm,right= 1cm of h2]   (a1) {};
\node[draw,circle,inner sep=1mm,left= 1cm of h1,label={[inner sep=0]-60:$-$}] (a2) {};
\draw[->] (h1) -| (a1) node[right,midway] {$y_1$};
\draw[->] (h2) -| (a2) node[left,midway] {$y_2$};
\draw[->] (a1) -- (h2) node[above,midway] {$e_2$};
\draw[->] (a2) -- (h1) node[above,midway] {$e_1$};
\draw[<-] (a1) -- +(1cm,0) node[right] {$u_2$};
\draw[<-] (a2) -- +(-1cm,0) node[left] {$u_1$};
\end{tikzpicture}
\caption{Negative feedback interconnection}%
\label{fig:lit:passint}%
\end{figure}

\subsection{$\mu-$analysis}
As given in \Cref{sec:lit:uncmodel}, stability in the face of uncertainties can also be analyzed in the generalized plant framework 
of robust control. After rewriting the signal relations, the teleoperation system can be written as an uncertain interconnection as 
shown in \Cref{fig:lit:uncincgeneral}. In this setting, $G$ is the model of the nominal bilateral teleoperation system and $\Delta$ 
is a block diagonal collection of uncertainties, such as the human, the environment, delays, etc. Stability tests are based on structural 
hypotheses on the diagonal blocks of the operator $\Delta$ such as gain bounds or passivity. These properties should allow us to develop 
numerically verifiable conditions for the system $G$ that guarantee interconnection stability. This is intuitive because we have no access 
to the actual $\Delta$ and we can only describe its components by means of indirect properties. 

If the interconnection subsystems are represented in the scattering parameters, the $\mu$ test is precisely equivalent to the test of
Llewellyn's theorem and often called as Rollett's stability parameter. This is due to the well-known equivalence between the small-gain 
and passivity theorem \cite{desvid}. We have to note that the equivalence is stated in terms of the stability characterization. Otherwise, 
small-gain theorem requires a normed space structure whereas passivity theorem requires an inner product space structure, hence the 
applicability is relatively limited. This is also related to the fact that we need to work with power variables exclusively in the 
passivity framework and this is not always convenient if the performance specifications are related to other variables.

In the literature, this analysis method often follows the scattering transformations such that, the passivity assumption avoids the
explicit modeling and small-gain theorem allows to handle the delay problem via with bounded operators.


We can also directly take the uncertain modeling of the human and the environment and utilize $\mu-$analysis for the teleoperation
system. 



\begin{figure}%
\centering%
\begin{tikzpicture}[>=stealth]
\node[draw,minimum size=0.75cm] (plant) at (0,0) {$G$};
\node[draw,minimum size=0.75cm] (unc) at (0,1.5) {$\Delta$};
\draw[->] (plant.west) -| ++(-5mm,10mm) node[left] {$v$} |- (unc.west);
\draw[->] (unc.east)   -| ++(5mm,-5mm) node[right] {$u$} |- (plant.east);
\end{tikzpicture}
\caption{Uncertain Interconnection}%
\label{fig:lit:uncincgeneral}%
\end{figure}



\subsection{Modeling the Communication Delay}

Over the past two decades, it has been confirmed in various studies that, if present, the communication delays are a major 
source of instability (reports date back to 60's, e.g., \cite{sheridanferrell} and the references in \cite{andersonspong}).
Even when the delay duration $t$ is known and constant, delay operator can be shown to be nonpassive since
$e^{-st}$ is not positive real. Hence, when combined with the passivity framework, it violates the assumptions on the uncertain
operators. 


At end of the 80's, two prominent studies (\cite{andersonspong,nieslotine}) proposed a direct handle to handle delay 
robustness problem using the scattering transformations. This notion is best explained by loop transformations since the 
original articles refer to microwave and transmission line theories which use quite specialized terminology. One can also
find the system theoretical view of these transformations in \cite{colgate3}. The key concept of the scattering transformation
or the wave variables methods is mapping the closed right half plane to the closed unit disk via bijective M\"{o}bius (or linear 
fractional or bilinear) transformations: 
 
\begin{equation}
W:[0,\infty]\times[\infty,\infty] \mapsto \left\{ z\in\Complex \mid \abs{z} \leq 1 \right\}\quad, \quad W(z) = \frac{z-1}{z+1}
\label{eq:lit:smith}
\end{equation}

One can directly verify that $1\to 0,\infty\to 1$ and $0\to -1$ under $s$. Pictorially, the mapping is given in 
\Cref{fig:lit:smith} using a Smith chart which is located at the origin. Hence, positive real transfer matrices
become norm bounded by $1$ such that we can analyze the interconnection using the small-gain theorem.


Since often omitted in the literature, let us demonstrate a few properties of this transformation. First, this mapping can be shown with
a block diagram. Assume an LTI SISO system $G(s)$ and let the input/output relation is given by $y=Gu$. Then, with a
standard manipulation, we obtain a feedback interconnection that leads to the mapping
\[
W(G(s)) = \frac{G(s)-1}{G(s)+1} = -1 + \frac{2G(s)}{G(s)+1} \Longrightarrow 
\begin{tikzpicture}[baseline=(g.center),scale=0.5,transform shape,every node/.style={draw,minimum size=1cm},every path/.style={->},>=stealth]
\node[draw] (g) at (0,0) {$G$};
\node[draw,left=1cm of g] (s1) {$\sqrt{2}$};
\node[draw,right=1cm of g] (s2) {$\sqrt{2}$};
\node[draw,circle, right=1cm of s2,minimum size=0,inner sep=3pt] (j) {};
\draw (s1) -- (g) node[midway,circle,fill=white,minimum size=2mm,inner sep=0] (f) {};
\draw ($(g)!0.5!(s2)$) |- ++(-1cm,-1cm) -| (f);
\draw (g) -- (s2);\draw (s2)--(j);\draw (j)--+(1cm,0);
\draw (s1) ++(-25mm,0) -- (s1);
\draw (s1) ++(-15mm,0) |- ([shift={(-1cm,1cm)}]j.center) -| (j);
\path (j)++(50:3mm) node[draw=none,minimum size=0,inner sep=3pt] {$-$};
\end{tikzpicture}
\]
The distribution of $\sqrt{2}$ is a matter of convention and provides symmetry in the block diagrams. Also we have, 
\begin{align*}
(W\circ W)(G) &= \frac{-1}{G},\\
(W\circ W \circ W) (G) &= \frac{-1}{W(G)},\\
(W\circ W \circ W \circ W) (G) &= G\\
\end{align*}
which is nothing but the $90^\circ$ rotations of the Riemann sphere about the axis parallel to the imaginary axis ($W$ is an element of 
M\"{o}bius group with $\circ$ operation). This is closely related to the stability parameter of Edwards and Sinsky (\cite{edsin}). 



\begin{figure}%
\centering
\begin{tikzpicture}[scale=0.7]
\begin{smithchart}[show origin,
axis background/.style={shading=eightball},
no marks,
grid=major,
axis equal,samples=150,
]
\foreach \t in {0,0.2,0.5,1}{
\addplot+[ultra thick,domain=-10:10] (\t,\x);
}

\end{smithchart}
\begin{scope}[shift={(8cm,0)}]
\begin{axis}[axis lines=middle,
grid=major,
no marks,
axis background/.style={right color=black!50,left color=white},
xmax=1.5,
ytick=\empty,
every axis/.append style={
extra description/.code={
\node[xshift=-5mm] at (0,1) {Im$(z)$};
\node[xshift=-5mm] at (1,0.55) {Re$(z)$};
}}]
\foreach \x in {0,0.2,0.5,1}{
\addplot+[ultra thick] coordinates {(\x,-10) (\x,10)};
}
\end{axis}
\end{scope}
\end{tikzpicture}
\caption[Mapping the closed right half plane onto the unit disc.]%
{Mapping the closed right half plane onto the unit disc. Origin on the right is mapped to the point $(-1,0)$ shown with a white dot on the left.}%
\label{fig:lit:smith}%
\end{figure}

Obviously once this transformation is introduced, there is a need for the ``inverse'' of $W$, such that the
loop equations remain unchanged, that is to say we have to introduce another transformation that undoes
$W$. The simplest way to obtain a mapping $\hat{W}$ is to follow the block diagram backwards as shown in 
\Cref{lit:syn:invscat}. Another block diagram reduction (or rotating three more times as shown above) shows that 
\[
\hat{W}(z) = -\frac{z+1}{z-1} = -\frac{1}{W(z)}
\]
The negative sign usually does not show up in the formulations because the passive interconnections 
require a sign change in the loop to indicate the ``from'' and ``to'' ports. A more detailed derivation
is given in \cite{colgate3}.


\begin{figure}%
\centering
\begin{tikzpicture}[scale=0.7,transform shape,every node/.style={draw,minimum size=1cm},every path/.style={->},>=stealth]
\node[draw] (g) at (0,0) {$G$};
\node[draw,left=1cm of g] (s1) {$\sqrt{2}$};
\node[draw,right=1cm of g] (s2) {$\sqrt{2}$};
\node[draw,circle, right=1cm of s2,minimum size=0,inner sep=3pt] (j) {};
\draw (s1) -- (g) node[midway,circle,fill=white,minimum size=2mm,inner sep=0] (f) {};
\draw ($(g)!0.5!(s2)$) |- ++(-1cm,-1cm) -| (f);
\draw (g) -- (s2);\draw (s2)--(j);
\draw (s1) ++(-15mm,0) |- ([shift={(-1cm,1.5cm)}]j.center) -| (j);
\path (j)++(50:3mm) node[draw=none,minimum size=0,inner sep=3pt] {$-$};
\node[draw] (h) at (0,-2cm) {$H$};
\node[draw,left=1cm of h] (is1) {$\frac{1}{\sqrt{2}}$};
\node[draw,right=1cm of h] (is2) {$\frac{1}{\sqrt{2}}$};
\node[draw,circle, right=1cm of is2,minimum size=0,inner sep=3pt] (j2) {};
\draw (j)-|++(1cm,-1cm)|-(j2);
\draw (h) -- (is1) node[midway,circle,fill=white,minimum size=2mm,inner sep=0] (f2) {};
\draw (is2) -- (h);\draw (j2)--(is2);
\draw ($(h)!0.5!(is2)$) |- ++(-1cm,-1cm) -| (f2);
\draw (is1) --++(-25mm,0) |- (s1);
\draw (is1) ++(-15mm,0) |- ([shift={(-1cm,-1.5cm)}]j2.center) -| (j2);
\path (f) ++(-70:5mm) node[draw=none] {$-$};
%\path (f2) ++(-70:5mm) node[draw=none] {$-$};
\end{tikzpicture}
\caption[Scattering transformation and its inverse.]{Scattering transformation and its inverse.}%
\label{lit:syn:invscat}%
\end{figure}


Under the mapping $W$, the Nyquist curve of $e^{-sT}$ (unit circle) is mapped onto the imaginary axis, 
hence unbounded. This once agin shows that delay uncertainty does not satisfy the norm constraint
$\|W(e^{-\iw t})\|_\infty \leq 1$ to invoke the small-gain theorem in the transformed coordinates. 
Had it been the case that the uncertainty was bounded by one, then it would have been possible to 
conclude stability directly in the passivity theorem. Thus, these transformations are not directly 
beneficial for analysis, however, following the cue from the previous mapping results, papers 
\cite{andersonspong} and \cite{nieslotine} 
made it possible to design controllers that takes into account this delay uncertainty. The resulting 
loop is stable regardless of delay period, hence they belong to the class of methods often distinguished
by ``delay-independent'' methods. According to the literature, these are the most common methods
applied in the face of delay uncertainty.

Another possibility is to utilize the simple fact that the delay operator is gain-bounded and obtain the 
generalized plant by pulling out the uncertainty out of the loop. Obviously, this would be a very crude
characterization of the unit circle since as unit disk is used as the uncertainty instead. 

Similar approach is reported in \cite{leungfa} using $\mu-$synthesis. But the authors have omitted 
the uncertainty of the human and the environment. Therefore, their analysis is only valid for nominal 
teleoperation systems. Though, this can be extended to more general cases, we have to note that, they 
don't consider the human as ``some impedance$+$state-independent force input'' but as an finite-energy
force input signal filtered through the human characteristics. Technically, this amounts to the common 
input-filtering often used in the $H_\infty$ design problems. 

 










\section{Synthesis}

Complementary to the analysis section, we cover a few popular controller design among many other except the 
art of control engineering, namely, the manual PID tuning. 

\subsection{Two-, Three-, and Four-Channel Control Architectures}
In the teleoperation literature, the control laws are categorized in terms of how many measurement signals 
are sent over to the opposite medium during the teleoperation for control and the actual controller synthesis method
that is, how we actually obtain the controller is often not considered in this classification.  Hence, the naming 
goes with ``$n-$channel control''. The naming scheme can be better visualized as shown in \Cref{lit:syn:ela}. 


\subsubsection{Position-Postion and Position-Force Controllers}
The simplest control architecture among all is probably the PERR (position error) control in which the 
position of both local and the remote site devices are collected by the controller and control input is
produced.

Assume that the local and the remote device are at rest at position $x=0$ in the respective world coordinates. 
Also assume that the user moves the local device to position $x=\SI{10}{\centi\metre}$. What the control algorithm
should do is to measure the position difference and force each device accordingly to minimize the error. Hence, the
control law is of the form
\[
\pmatr{F_l\\F_r} = \pmatr{-1\\1} K_p(s) (x_l-x_r).
\]
where $F_r,F_l$ denote the control action at the local and the remote sites. $K(s)$ can be a constant or a SISO dynamical 
system or any other esoteric control law. One can perform the same with velocity signals (to comply with the passivity 
analysis) if available in noise-free measurements. Otherwise, position drift is unaviodable even with integral action. 

Typically, this control architecture would give a sluggish performance since there is no preference or priority in 
correcting the error signal on each side. Therefore, while the remote site is pulled forward to track the local device,
simultaneously, the local device is pulled back with the same force. This results with a feel similar to extending a 
damper, only in this case, it softens up according to the position error instead of travel velocity.

Another widely used, control architecture is the so-called Position-Force Controller. In this method the first channel 
in the PERR control structure is replaced with the remote site force input. Hence, local site device tracks the remote site 
encountered force while the remote site device tracks the position of the local site device. 
\[
\pmatr{F_l\\F_r} = \pmatr{K_f(s)F_{env} \\ K(s) (x_l-x_r)}.
\]
Clearly, the side-effect of PERR type control is avoided since the position and force errors are tracked independently 
in two seperate channels. But this brings in another tuning problem: If the position control gain dominates, the force tracking 
behaves aggresively in the hard contact case due to the overuse of control action to drive the remote device into the obstacle
and generally results with kickback or the local device. Conversely, domination of the force gain results with chattering of 
the remote device on the obstacle due to the discontinuous nature of the force reference signal if the user touches the handle 
with just softly enough to sustain an oscillation. Therefore, not only the gains of the individual channels are hard to tune, but
also relative magnitudes of the gains makes the tuning more tedious.

\subsubsection{Force-Force+PERR}

To increase the bandwidth and to reduce the side-effects of aforementioned methods, a feedforward controller is added to the 
position-force control architecture. 
\[
\pmatr{F_l\\F_r} = \pmatr{K_{f1}(s)F_{env} \\ K(s) (x_l-x_r)+K_{f2}(s)F_{hum}}.
\]
Hence, the name a three-channel controller. This has been introduced in \cite{hashzaad1999} and also analyzed in CITE!.

\subsubsection{Lawrence Control Architecture}

In \cite{lawrence}, a general control scheme is proposed (later extended by \cite{salcudeanzhu,hzaadsalcu2}). In this architecture, 
also the remaining channel of remote position is sent over to the local site, completing the number of channels transmitted to four.
The individual controller blocks and the resulting overall block diagram is shown in \Cref{lit:syn:ela}.  

\begin{figure}%
\centering
\begin{tikzpicture}[
imp/.style={draw,inner sep=4pt},
impc/.style={draw,inner sep=4pt,ultra thick},
junc/.style={draw,circle,inner sep=3pt},>=stealth]
\begin{scope}[xshift=-3cm]
\node[impc] (c4) at (0,0) {$C_4$};
\node[impc] (c3) at (2cm,0cm) {$C_3$};
\node[impc] (c2) at (4cm,0cm) {$C_2$};
\node[impc] (c1) at (6cm,0cm) {$C_1$};

\node[imp] (zinvs) at (1cm,2cm) {$Z_s^{-1}$};
\node[impc] (cs) at (1cm,3cm) {$C_s$};
\node[impc] (c5) at (5cm,3cm) {$C_5$};
\node[imp] (ze) at (3cm,5cm) {$Z_e$};

\node[imp] (zinvm) at (5cm,-2cm) {$Z_m^{-1}$};
\node[impc] (cm) at (5cm,-3cm) {$C_m$};
\node[impc] (c6) at (1cm,-3cm) {$C_6$};
\node[imp] (zh) at (3cm,-5cm) {$Z_h$};
\end{scope}
\foreach \x in {1,4}{
\draw[dotted] (-3.5cm,\x) --(3.5cm,\x) (-3.5cm,-\x) --(3.5cm,-\x);
}
\foreach \x[count=\xi] in {(0.25,2),(3,5),(0,-2),(-3,-5)}{
\node[junc] (j\xi) at \x {};
}
\draw[->] (zinvs.west) -| (c4);
\draw[->] (zinvs.east -| c4) |- (cs.west);
\draw[->] (cs-|c4) |- (ze);
\draw[->] (ze) -- (j2);
\draw[->] (j2) |- (c5);
\draw[->] (j2 |- c5) |- (j1);
\draw[->] ({{j2 |- j1}}-| c2) -- (c2.north);
\draw[->] (c1.north) -- ++(0,2mm) --(j1.-45);
\draw[->] (cs.east) -- ++(5mm,0) --(j1);
\draw[->] (j1) -- (zinvs);
\draw[->] (c5.west) -- ++(-5mm,0) --(j1);
\draw[->] (c3.north) -- ++(0,5mm) --(j1);

\draw[->] (zinvm.east) -| (c1);
\draw[->] (zinvm.east -| c1) |- (cm.east);
\draw[->] (cm-|c1) |- (zh);
\draw[->] (zh) -- (j4);
\draw[->] (j4) |- (c6);
\draw[->] (j4 |- c6) |- (j3);
\draw[->] ({{j4 |- j3}}-| c3) -- (c3.south);

\draw[->] (c4.south) -- ++(0,-2mm) --(j3.135);
\draw[->] (cm.west) -- ++(-5mm,0) --(j3);
\draw[->] (j3) -- (zinvm);
\draw[->] (c6.east) -- ++(5mm,0) -- (j3);
\draw[->] (c2.south) -- ++(0,-5mm) --(j3);

\draw[<-] (j2) -- ++(8mm,0) node[midway,above] {$f^*_e$}; 
\draw[<-] (j4) -- ++(-8mm,0) node[midway,above] {$f^*_h$};

\path (j2) ++(200:4mm) node {$\scriptstyle-$};
\foreach \x/\y in {20/+,60/-,120/-,240/+,-20/-}{
\draw (j1) ++(\x:5mm)node   {$\scriptstyle\y$};
}
\foreach \x/\y in {160/+,120/-,60/-,-60/-,200/+}{
\draw (j3) ++(\x:5mm)node   {$\scriptstyle\y$};
}
\end{tikzpicture}
\caption[Extended Lawrence Architecture]{Extended Lawrence Architecture, adapted from \cite{hashzaad1999}. 
Starred signals are the exogenous force inputs by the human/environment}%
\label{lit:syn:ela}%
\end{figure}


Instead of such classification, one can directly start with a MIMO control structure and avoid 
such classifications while keeping the control problem formulation fixed. For this purpose, consider the 
control mapping $K:\Real^{n_1}\times\Real^{n_2}\times\Real^3\times\Real^3\to \Real^{m_1}\times\Real^{m_2}$ from the 
measurements to the local and remote control actions via 
\begin{equation}
\pmatr{F_l\\F_r} = K \pmatr{x_l\\x_r\\F_{hum}\\F_{env}} 
\vcentcolon = 
\tikz[baseline=(m.center),
every left delimiter/.style={xshift=1ex},%tighter delimiter spacing
every right delimiter/.style={xshift=-1ex}]
{\matrix[matrix of math nodes,
ampersand replacement=\&,
left delimiter={[},
right delimiter={]},
nodes={minimum width=1cm}
](m){
-C_m \& |[fill=gray]| C_4 \& C_5 \& |[fill=gray]|-C_2\\ 
|[fill=gray]|C_1  \& C_s \& |[fill=gray]|C_3 \& -C_6\\
};
}
\pmatr{x_l\\x_r\\F_{hum}\\F_{env}}
\label{eq:lit:MIMOcont}
\end{equation}
where $n_1,n_2$ denote the number position measurements and $m_1,m_2$ denote the actuation inputs with overactuated 
robotic manipulators in mind. The grayed entries are the control subcomponents that works with the variables sent over 
the network. If we recap the architectures above with this notation, they can be represented as
\[
K = \bmatr{
-k &k&0&0\\
k&-k&0&0
}\pmatr{x_l\\x_r\\F_{hum}\\F_{env}},
\]
\[
K = \bmatr{
0&0&0&k_f\\
k&-k&0&0
}\pmatr{x_l\\x_r\\F_{hum}\\F_{env}},
\]
\[
K = \bmatr{
0&0&0&k_{f1}\\
k&-k&0&k_{f2}
}\pmatr{x_l\\x_r\\F_{hum}\\F_{env}}
\]
respectively. Each of the lower case $k_i$ represents some constant or dynamic controller. Obviously, one can 
generate many more architectures populating different entries and the zero blocks. 






\subsection{Time-Domain Passivity Control}
